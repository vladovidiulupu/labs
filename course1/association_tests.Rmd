---
title: "Association tests"
output: pdf_document
layout: page
---

```{r options, echo=FALSE}
library(knitr)
opts_chunk$set(fig.path=paste0("figure/", sub("(.*).Rmd","\\1",basename(knitr:::knit_concord$get('infile'))), "-"))
```

```{r,include=FALSE}
set.seed(1)
```

# Introduction

The statistical tests we have covered up to know leave out a substantial portion of life science projects. Specifically, we are referring to data that is binary, categorical and ordinal. To give a very specific example, consider genetic data where you have two genotypes (AA/Aa or aa) for cases and controls for a given disease. The statistical question is if genotype and disease are associated. Note that as in the examples we have been studying we have two populations: AA/Aa and aa and  numeric data for each. So why can't we perform a t-test? Note that the data is either 0 (control) or 1 (cases). It is pretty clear that this data is not normally distributed so the t-distribution approximation is for sure out of the question. We could use CLT if the sample size is large enough, but instead we can use association tests.

# Association tests

One of the most famous examples of hypothesis testing was performed by RA Fisher on a lady that claimed could tell if milk was added before or after the tea was poured. Fisher gave the lady four pairs of cups of tea: one with milk poured first, the other after. The order was randomized. Say the lady picked 3 out 4 correctly, do we believe she has a special ability? Hypothesis testing helps answer this question by quantifying what happens by chance.

The basic question we ask is: if the lady is just guessing, what are the chances that she gets 3 or more correct? Just as we have done before we can compute a probability under the null that hypothesis that she is just guessing. If we assume the lady is just guessing randomly, we can think of this particular examples as picking 4 balls out of an urn with 4 green (correct answer) and 4 red (incorrect answer) balls. 

Under the null hypothesis that the lady is just guessing each ball has the same chance of being picked. We can then use combinatorics to figure out the probability. The probability of picking 3 is ${4 \choose 3} {4 \choose 1} / {8 \choose 4} = 16/70$. The probability of picking all correct is ${4 \choose 4} {4 \choose 0}/{8 \choose 4}= 1/70$. Thus the chance of observing a 3 or something more extreme, under the null hypothesis, is 0.24. This is called a p-value. This is called Fisher's exact test and it uses the hyper geometric distribution.

## Two by two tables

Note that the data from the experiment above can be summarized by a 2 by 2 tables:

```{r}
tab <- matrix(c(3,1,1,3),2,2)
rownames(tab)<-c("Poured Before","Poured After")
colnames(tab)<-c("Guessed before","Guessed after")
tab
```

The function `fisher.test` performs the calculations above and can be obtained like this:

```{r}
fisher.test(tab,alternative="greater")
```

## Chi-square test

Genome-wide association studies (GWAS) have become ubiquitous in Biology. One of the main statistical summaries used in these studies are Manhattan plots. The y-axis of a Manhattan plot typically represents the negative of log (base 10) of the p-values obtained for association tests applied at millions of single nucleotide polymorphisms (SNP). These p-values are obtained in a similar way to the test performed on the tea tasting lady. However in that example the number of green and red balls is experimentally fixed and the number of answers given for each category is also fixed. Another way to say this is that the sum of the rows and the sum of the columns are fixed. This defines constraints on the possible ways we can fill the 2 by 2 table and also permits us to use the hypergeometric distribution. In general, this is not the case. But there is another approach which is the Chi-squared test described here.

Imagine we have 280 individuals, some of them have a given disease others donâ€™t. We observe that a 20% of the individuals that are homozygous for the minor allele (aa) have the disease compared to 10% of the rest. Would we see this again if we picked another 220 individuals?

Let's create an dataset with these perencentages:

```{r}
disease=factor(c(rep(0,180),rep(1,20),rep(0,40),rep(1,10)),
               labels=c("control","cases"))
genotype=factor(c(rep("AA/Aa",200),rep("aa",50)),
                levels=c("AA/Aa","aa"))
dat <- data.frame(disease, genotype)
dat <- dat[sample(nrow(dat)),]##shuffle them up
head(dat)
```

To create the appropriate two by two table we will use the function `table`. This function tabulates the frequency of each level in a factor. For exampel:

```{r}
table(genotype)
table(disease)
```

If you you feed the function two factors it will tabulate all possible pairs and thus create the two by two table:

```{r}
tab <- table(genotype,disease)
tab
```

Note that you can feed `table` $n$ factors and it will tabulate all $n$-tubles.

The typical statistics we use to summarize these results is the odds ratio (OR). We compute the odds of having the disease if you are an "aa": 10/40, the odds of having the disease if you are an "AA/Aa": 20/180, and take the ration: $(10/40) / (20/180)$ 

```{r}
(tab[2,2]/tab[2,1]) / (tab[1,2]/tab[1,1])
```

Now to compute p-value we don't use the OR directly, we assume that there is no association between genotype and disease and compute what we expect to see in each cell. Note under the null that 200 and 50 individuals in each group were assigned disease with the same probability. If this is the case then the probability of disease is

```{r}
p=mean(disease=="cases")
p
```

The expected table is therefore

```{r}
expected <- rbind(c(1-p,p)*sum(genotype=="AA/Aa"),
                  c(1-p,p)*sum(genotype=="aa"))
dimnames(expected)<-dimnames(tab)
expected
```

The Chi-square test uses an asymptotic result (similar to CLT) about the sums of independent binary outcomes, we can compute an approximate probability of seeing a deviation for the expected table as big as this one. The p-value for this table is 

```{r}
chisq.test(tab)$p.value
```

## Large samples, small p-values

As we mentioned earlier reporting only p-values is not an appropriate way to report the results of your experiment. Many genetic association studies seem to over emphasize p-values. They have large sample sizes, report impressively small p-values, yet when one looks closely at the results, we realize odds ratios are quite modest: barely bigger than 1.

We note that there is not a one to one relationship between the odds ratio and the p-value. To demonstrate we re calculate the p-value keeping all the proportions identical but increasing the sample size by 10 which reduces the p-value substantially

```{r}
tab<-tab*10
chisq.test(tab)$p.value
```

## Confidence intervals for the odd ratio

Computing confidence intervals for the OR is not mathematically straightforward. Unlike other statistics for which we have found approximations for their distributions, the OR is not only a ratio, but a ratio of ratio and there is not simple way of using, for example, the CLT.
 
 One approach is to use the theory of generalized linear models which provides estimates of the log odds ratio, rather than the OR itself, that can be shown to be asymptotically normal. Here we provide R code without much details of what it is:
  
```{r}
fit <- glm(disease~genotype,family="binomial",data=dat)
coeftab<- summary(fit)$coef
coeftab
```

The second row of the table shown above gives you the estimate and SE of the log odds ratio and mathematical theory tells us the this estiamte is approximately normally distributed. We can therefore form a confidence interval and then exponentiate to provide a confidence interval for the OR.

```{r}
ci <- coeftab[2,1] + c(-2,2)*coeftab[2,2]
exp(ci)
```

Note that the confidence includes 1, which is consistent with the p-value being bigger than 0.05. Also note that the p-value shown here is based on a different approximation to the one used by the Chi-square test which is why they differ.

